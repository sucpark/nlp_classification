{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "from model.metric import evaluate, predicate, acc, LSR\n",
    "from model.data import DAdataset\n",
    "from model.net import LSTMClassifier\n",
    "from model.utils import remove_punct, sent_tokenize, stemming, lemmatize, preprocess_text\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = Path('..')\n",
    "data_dir = home_dir / 'dataset' / 'SDAC'\n",
    "save_dir = home_dir / 'experiment' / 'SDAC'\n",
    "train_data_name = 'sw_train.txt'\n",
    "valid_data_name = 'sw_val.txt'\n",
    "test_data_name = 'sw_test.txt'\n",
    "# pretrained_embeddings_name = 'embeddings.pkl'\n",
    "token2idx_name = 'word2idx.json'\n",
    "label2idx_name = 'label2idx.json'\n",
    "config_name = 'config.json'\n",
    "    \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(embedding_dim=128, epochs=100, hidden_size=256, lr=1e-05, max_len=256, n_batch=64, n_layers=1, summary_step=10000)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"epochs\": 100,\n",
    "    \"n_batch\": 64,\n",
    "    \"max_len\": 256,\n",
    "    \"lr\": 1e-5,\n",
    "    \"summary_step\": 10000,\n",
    "    \"embedding_dim\": 128,\n",
    "    \"hidden_size\": 256,\n",
    "    \"n_layers\": 1,\n",
    "}\n",
    "args = argparse.Namespace(**args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_dir / pretrained_embeddings_name, 'rb') as f:\n",
    "#     pretrained_embeddings = pickle.load(f)\n",
    "    \n",
    "with open(data_dir / token2idx_name, 'r') as f:\n",
    "    token2idx = json.load(f)\n",
    "    \n",
    "with open(data_dir / label2idx_name, 'r') as f:\n",
    "    label2idx = json.load(f)\n",
    "    \n",
    "with open(data_dir / config_name, 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "idx2token = {i:t for t,i in token2idx.items()}\n",
    "idx2label = {i:l for l,i in label2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 \n",
    "\n",
    "train_data = pd.read_csv(data_dir / train_data_name, header=None, sep='|', names=['speaker','utterance','tag'])\n",
    "valid_data = pd.read_csv(data_dir / valid_data_name, header=None, sep='|', names=['speaker','utterance','tag'])\n",
    "\n",
    "\n",
    "x_train, y_train = train_data['utterance'], train_data['tag']\n",
    "x_valid, y_valid = valid_data['utterance'], valid_data['tag']\n",
    "\n",
    "text_preprocess_pipeline = [sent_tokenize, stemming] # 이전에 해줬던 전처리 과정과 동일하게 해줘야 함\n",
    "\n",
    "x_train = x_train.apply(preprocess_text, processing_function_list=text_preprocess_pipeline)\n",
    "x_valid = x_valid.apply(preprocess_text, processing_function_list=text_preprocess_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 구성\n",
    "\n",
    "x_train = list(convert_token_to_idx(x_train, token2idx))\n",
    "x_valid = list(convert_token_to_idx(x_valid, token2idx))\n",
    "\n",
    "y_train = list(convert_label_to_idx(y_train, label2idx))\n",
    "y_valid = list(convert_label_to_idx(y_valid, label2idx))\n",
    "\n",
    "tr_ds = DAdataset(x_train, y_train)\n",
    "tr_dl = DataLoader(tr_ds, batch_size=args.n_batch, collate_fn=tr_ds.collate_fn, shuffle=True, drop_last=True)\n",
    "\n",
    "val_ds = DAdataset(x_valid, y_valid)\n",
    "val_dl = DataLoader(val_ds, batch_size=args.n_batch, collate_fn=val_ds.collate_fn, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "\n",
    "learning_rate = args.lr\n",
    "batch_size = args.n_batch\n",
    "vocab_size = len(token2idx)\n",
    "embedding_dim = args.embedding_dim\n",
    "hidden_size = args.hidden_size\n",
    "output_size = len(label2idx)\n",
    "n_layers = args.n_layers\n",
    "dropout = 0.7\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(batch_size, output_size, hidden_size, vocab_size, n_layers, embedding_dim, device,\n",
    "                       dropout=dropout, bidirectional=True) #, weights=torch.from_numpy(pretrained_embeddings))\n",
    "\n",
    "loss_fn = LSR(epsilon=0.1, num_classes=output_size)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "\n",
    "writer = SummaryWriter(f'{save_dir}/runs')\n",
    "checkpoint_manager = CheckpointManager(save_dir)\n",
    "summary_manager = SummaryManager(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245fc99a55cd40239d0fc2dc75695346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='epochs'), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73459dd271274094ac6ae4000553408a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='steps'), FloatProgress(value=0.0, max=3006.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "steps: 100%|██████████| 51/51 [00:00<00:00, 267.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      "global_Step:   0, tr_loss: 1.251260, val_loss: 1.245575\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\n",
    "best_val_loss = 1e+10\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "x_error_check = []  # Issue 에 대한 디버깅 코드\n",
    "\n",
    "for epoch in tqdm(range(args.epochs), desc='epochs'):\n",
    "    tr_loss = 0\n",
    "    tr_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for step, mb in tqdm(enumerate(tr_dl), desc='steps', total=len(tr_dl)):\n",
    "        x_mb, y_mb = map(lambda elm: elm.to(device), mb)\n",
    "        \n",
    "        x_error_check.append(x_mb)\n",
    "        if len(x_error_check) > 2:\n",
    "            del x_error_check[0]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_hat_mb = model(x_mb)\n",
    "        loss = loss_fn(y_hat_mb, y_mb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            mb_acc = acc(y_hat_mb, y_mb)\n",
    "        \n",
    "        clip_gradient(model, 1e-1)\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        tr_acc += mb_acc.item()\n",
    "        \n",
    "        if (epoch*len(tr_dl)+step) % args.summary_step == 0:\n",
    "            val_loss = evaluate(model, val_dl, {'loss':loss_fn}, device)['loss']\n",
    "            writer.add_scalars('loss', {'train': tr_loss / (step + 1), 'val': val_loss}, epoch*len(tr_dl) + step)\n",
    "            tqdm.write('global_Step: {:3}, tr_loss: {:3f}, val_loss: {:3f}'.format(epoch* len(tr_dl) + step,\n",
    "                                                                                       tr_loss / (step + 1),\n",
    "                                                                                       val_loss))\n",
    "            model.train()\n",
    "    \n",
    "    else:\n",
    "        tr_loss  /= (step + 1)\n",
    "        tr_acc /= (step + 1)\n",
    "        train_losses.append(tr_loss)\n",
    "        train_acc.append(tr_acc)\n",
    "        \n",
    "        tr_sum = {'loss': tr_loss, 'acc': tr_acc}\n",
    "        val_sum = evaluate(model, val_dl, {'loss': loss_fn, 'acc': acc}, device)\n",
    "        tqdm.write('epoch : {}, tr_loss: {: 3f}, val_loss: '\n",
    "                       '{:.3f}, tr_acc: {:.2%}, val_acc: {:.2%}'.format(epoch+1, tr_sum['loss'], val_sum['loss'],\n",
    "                                                                        tr_sum['acc'], val_sum['acc']))\n",
    "        \n",
    "        val_loss = val_sum['loss']\n",
    "        valid_losses.append(val_loss)\n",
    "        valid_acc.append(val_sum['acc'])\n",
    "        is_best = val_loss < best_val_loss\n",
    "        \n",
    "        if is_best:\n",
    "            state = {\n",
    "                'epoch': epoch+1, \n",
    "                'model_state_dict': model.state_dict(), \n",
    "                'opt_state_dict': optimizer.state_dict()\n",
    "            }\n",
    "            summary = {'tr': tr_sum, 'val': val_sum}\n",
    "            summary_manager.update(summary)\n",
    "            summary_manager.save('summary.json')\n",
    "            checkpoint_manager.save_checkpoint(state, 'best.tar')\n",
    "            best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. jupyter notebook 버전이 다르면 tqdm이 안예쁘게 나올 수 있음\n",
    "    2. gpu를 안쓸경우 생각보다 오래 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Issue) 갑자기 아래의 에러가 나는 경우\n",
    "    \n",
    "    (Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.FloatTensor instead \n",
    "     while checking arguments for embedding)\n",
    "    \n",
    "    tr_dl 에서 나오는 index가 갑자기 소수점으로 바뀌는 경우가 있음. \n",
    "    위 에러가 뜬 뒤, x_mb.dtype 을 확인해보면 데이터 타입이 torch.float32 로 바뀌어 있음.\n",
    "    아마, batch 의 첫 번째 row가 empty일때, 이를 빼고 배치를 계산한뒤 다시 복구시킬때 gpu 에서 소수점으로 반환하는듯 \n",
    "    (torch gpu 초기값 문제일수도 있음)\n",
    "    \n",
    "    해결) 데이터 전처리시, punctuation 을 제거하지 않음. 문장중에 . 혹은 ? 만 있는 문장이 있기 때문에 empty sentence가 생김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(valid_losses)+1), valid_losses, label='Validation Loss')\n",
    "\n",
    "minposs = valid_losses.index(min(valid_losses))+1\n",
    "plt.axvline(minposs, linestyle='dotted', color='r',label='Best Model Checkpoint')\n",
    "\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f'{save_dir}/loss_plot.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_acc)+1), train_acc, label='Training Accuracy')\n",
    "plt.plot(range(1,len(valid_acc)+1), valid_acc, label='Validation Accuracy')\n",
    "\n",
    "minposs = valid_losses.index(min(valid_losses))+1\n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Best Model Checkpoint')\n",
    "\n",
    "plt.title('Accuracy Plot')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f'{save_dir}/accuracy_plot.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Label 이 존재할 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_dir / test_data_name, header=None, sep='|', names=['speaker','utterance','tag'])\n",
    "\n",
    "x_test, y_test = test_data['utterance'], test_data['tag']\n",
    "\n",
    "text_preprocess_pipeline = [sent_tokenize, stemming]\n",
    "x_test = x_test.apply(preprocess_text, processing_function_list=text_preprocess_pipeline)\n",
    "\n",
    "x_test = list(convert_token_to_idx(x_test, token2idx))\n",
    "y_test = list(convert_label_to_idx(y_test, label2idx))\n",
    "\n",
    "test_ds = DAdataset(x_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=64, collate_fn=test_ds.collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = evaluate(model, test_dl, {'loss': loss_fn, 'acc': acc}, device)\n",
    "\n",
    "summary_manager = SummaryManager(save_dir)\n",
    "summary_manager.load('summary.json')\n",
    "summary_manager.update(summ)\n",
    "summary_manager.save('summary.json')\n",
    "\n",
    "print('loss: {:3f}, acc: {:.2%}'.format(summ['loss'], summ['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222\n",
    "https://quokkas.tistory.com/entry/pytorch%EC%97%90%EC%84%9C-EarlyStop-%EC%9D%B4%EC%9A%A9%ED%95%98%EA%B8%B0\n",
    "https://simonjisu.github.io/nlp/2018/07/05/packedsequence.html\n",
    "https://nbviewer.jupyter.org/github/simonjisu/pytorch_tutorials/blob/master/00_Basic_Utils/02_PackedSequence.ipynb\n",
    "\n",
    "데이터 전처리: https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=qbxlvnf11&logNo=221434157182\n",
    "\n",
    "pretrained 사용: https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
